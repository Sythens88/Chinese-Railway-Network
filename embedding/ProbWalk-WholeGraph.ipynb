{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prob Walk on Whole Graph\n",
    "\n",
    "ProbWalk: Since the graph is a weighted graph, we will change to ProbWalk in random walk. For a node $u$, suppose its neighbours are $\\{v_1,v_2,...,v_n\\}$ and the relative weight of the edge is $w_1,w_2,...,w_n$. Then we will move to $v_i$ with probability $\\frac{w_i}{\\sum_{j=1}^n w_j}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as tud\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.read_edgelist('../graph/whole_undirected_graph.g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2826\n"
     ]
    }
   ],
   "source": [
    "nodes = list(graph.nodes)\n",
    "print(len(nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WALK_LENGTH = 20\n",
    "WALK_PER_VERTEX = 20\n",
    "WINDOW_SIZE = 2\n",
    "K = 5\n",
    "BATCH_SIZE = 128\n",
    "EMBED_DIM = 8\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "LEARNING_RATE = 0.2\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "node2idx = {node:i for i,node in enumerate(nodes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_count = [sum([value['weight'] for value in graph[node].values()]) for node in nodes]\n",
    "node_count = np.array(node_count)\n",
    "node_freq = node_count/np.sum(node_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProbWalk(graph,node,walk_length):\n",
    "    path = [node]\n",
    "    for _ in range(walk_length):\n",
    "        neighbour = graph[node]\n",
    "        prob = np.array([value['weight'] for value in neighbour.values()])\n",
    "        prob = prob/np.sum(prob)\n",
    "        node_next = np.random.choice(list(neighbour.keys()),1,p=prob)\n",
    "        path.append(node_next[0])\n",
    "        node = node_next[0]\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56520\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "for _ in range(WALK_PER_VERTEX):\n",
    "    for node in graph.nodes:\n",
    "        corpus.append(ProbWalk(graph,node,WALK_LENGTH))\n",
    "\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_pairs = []\n",
    "for path in corpus:\n",
    "    for i in range(len(path)):\n",
    "        idxs = (list(range(i-WINDOW_SIZE, i)) + list(range(i+1, i+WINDOW_SIZE+1)))\n",
    "        idxs = [idx for idx in idxs if idx>=0 and idx<=WALK_LENGTH]\n",
    "        if len(idxs)==2*WINDOW_SIZE:\n",
    "            pos_pairs += [ [path[i],[path[idx] for idx in idxs] ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(tud.Dataset):\n",
    "    def __init__(self,pos_pairs,node2idx,node_freq,K):\n",
    "        super(GraphDataset,self).__init__()\n",
    "        \n",
    "        self.center_node = [ node2idx[pair[0]] for pair in pos_pairs] \n",
    "        self.pos_pairs = [[node2idx[p] for p in pair[1]] for pair in pos_pairs]\n",
    "        self.center_node = torch.Tensor(self.center_node).long()\n",
    "        self.pos_pairs = torch.Tensor(self.pos_pairs).long()\n",
    "        self.node_freq = torch.Tensor(node_freq)\n",
    "        self.K = K\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.center_node)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        center_node = self.center_node[idx]\n",
    "        pos_nodes = self.pos_pairs[idx]\n",
    "        neg_nodes = torch.multinomial(self.node_freq, self.K * pos_nodes.shape[0], True)\n",
    "        \n",
    "        return center_node, pos_nodes, neg_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GraphDataset(pos_pairs,node2idx,node_freq,K)\n",
    "dataloader = tud.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self,node_size,embed_dim):\n",
    "        super(NodeEmbedding,self).__init__()\n",
    "        self.node_size = node_size\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        self.in_embed = nn.Embedding(node_size,embed_dim)\n",
    "        self.out_embed = nn.Embedding(node_size,embed_dim)\n",
    "        \n",
    "        initrange = 0.5/embed_dim\n",
    "        self.in_embed.weight.data.uniform_(-initrange, initrange)\n",
    "        self.out_embed.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "    def forward(self, center_node, pos_nodes, neg_nodes):\n",
    "        \n",
    "        center_emb = self.in_embed(center_node)   # bs*emb_dim\n",
    "        pos_emb = self.out_embed(pos_nodes) # bs*(2*ws)*emb_dim\n",
    "        neg_emb = self.out_embed(neg_nodes) # bs*(2*ws*K)*emb_dim\n",
    "        \n",
    "        loss_pos = torch.bmm(pos_emb, center_emb.unsqueeze(2)).squeeze()  # bs*(2*ws)\n",
    "        loss_neg = torch.bmm(neg_emb, -center_emb.unsqueeze(2)).squeeze() # bs*(2*ws*K)\n",
    "\n",
    "        loss_pos = F.logsigmoid(loss_pos).sum(1)\n",
    "        loss_neg = F.logsigmoid(loss_neg).sum(1) # batch_size\n",
    "       \n",
    "        loss = loss_pos + loss_neg\n",
    "        \n",
    "        return -loss\n",
    "    \n",
    "    def get_embed(self):\n",
    "        return self.in_embed.weight.data.cpu().numpy().tolist()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NodeEmbedding(len(graph.nodes),EMBED_DIM)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 0, loss: 16.63621711730957\n",
      "epoch: 0, iter: 2000, loss: 16.536460876464844\n",
      "epoch: 0, iter: 4000, loss: 11.974739074707031\n",
      "epoch: 0, iter: 6000, loss: 9.352302551269531\n",
      "epoch: 1, iter: 0, loss: 7.949399948120117\n",
      "epoch: 1, iter: 2000, loss: 7.548018455505371\n",
      "epoch: 1, iter: 4000, loss: 6.458703994750977\n",
      "epoch: 1, iter: 6000, loss: 5.635746002197266\n",
      "epoch: 2, iter: 0, loss: 5.333491802215576\n",
      "epoch: 2, iter: 2000, loss: 4.240967750549316\n",
      "epoch: 2, iter: 4000, loss: 4.627237319946289\n",
      "epoch: 2, iter: 6000, loss: 4.145338535308838\n",
      "epoch: 3, iter: 0, loss: 3.764333724975586\n",
      "epoch: 3, iter: 2000, loss: 3.8209946155548096\n",
      "epoch: 3, iter: 4000, loss: 3.3074119091033936\n",
      "epoch: 3, iter: 6000, loss: 3.1602931022644043\n",
      "epoch: 4, iter: 0, loss: 3.1610631942749023\n",
      "epoch: 4, iter: 2000, loss: 3.0098822116851807\n",
      "epoch: 4, iter: 4000, loss: 3.1721277236938477\n",
      "epoch: 4, iter: 6000, loss: 2.68496036529541\n",
      "epoch: 5, iter: 0, loss: 2.9439830780029297\n",
      "epoch: 5, iter: 2000, loss: 2.6889724731445312\n",
      "epoch: 5, iter: 4000, loss: 2.555751323699951\n",
      "epoch: 5, iter: 6000, loss: 2.475888729095459\n",
      "epoch: 6, iter: 0, loss: 2.3877124786376953\n",
      "epoch: 6, iter: 2000, loss: 2.5121021270751953\n",
      "epoch: 6, iter: 4000, loss: 2.2607693672180176\n",
      "epoch: 6, iter: 6000, loss: 2.3448214530944824\n",
      "epoch: 7, iter: 0, loss: 2.0421409606933594\n",
      "epoch: 7, iter: 2000, loss: 2.2999916076660156\n",
      "epoch: 7, iter: 4000, loss: 1.9351942539215088\n",
      "epoch: 7, iter: 6000, loss: 2.192410945892334\n",
      "epoch: 8, iter: 0, loss: 2.0483226776123047\n",
      "epoch: 8, iter: 2000, loss: 1.8910441398620605\n",
      "epoch: 8, iter: 4000, loss: 1.8434240818023682\n",
      "epoch: 8, iter: 6000, loss: 1.900719404220581\n",
      "epoch: 9, iter: 0, loss: 2.2299044132232666\n",
      "epoch: 9, iter: 2000, loss: 1.891848087310791\n",
      "epoch: 9, iter: 4000, loss: 1.9169113636016846\n",
      "epoch: 9, iter: 6000, loss: 1.623934030532837\n",
      "epoch: 10, iter: 0, loss: 2.1791672706604004\n",
      "epoch: 10, iter: 2000, loss: 1.5563852787017822\n",
      "epoch: 10, iter: 4000, loss: 1.6123502254486084\n",
      "epoch: 10, iter: 6000, loss: 1.3936794996261597\n",
      "epoch: 11, iter: 0, loss: 1.7471411228179932\n",
      "epoch: 11, iter: 2000, loss: 1.5392166376113892\n",
      "epoch: 11, iter: 4000, loss: 1.580669641494751\n",
      "epoch: 11, iter: 6000, loss: 1.611774206161499\n",
      "epoch: 12, iter: 0, loss: 1.8080480098724365\n",
      "epoch: 12, iter: 2000, loss: 1.764257550239563\n",
      "epoch: 12, iter: 4000, loss: 1.919309139251709\n",
      "epoch: 12, iter: 6000, loss: 1.6112605333328247\n",
      "epoch: 13, iter: 0, loss: 1.7172560691833496\n",
      "epoch: 13, iter: 2000, loss: 1.811044454574585\n",
      "epoch: 13, iter: 4000, loss: 1.4850183725357056\n",
      "epoch: 13, iter: 6000, loss: 1.610741376876831\n",
      "epoch: 14, iter: 0, loss: 1.5399088859558105\n",
      "epoch: 14, iter: 2000, loss: 1.4761006832122803\n",
      "epoch: 14, iter: 4000, loss: 1.5282227993011475\n",
      "epoch: 14, iter: 6000, loss: 1.4400135278701782\n",
      "epoch: 15, iter: 0, loss: 1.3959717750549316\n",
      "epoch: 15, iter: 2000, loss: 1.6435487270355225\n",
      "epoch: 15, iter: 4000, loss: 1.4906147718429565\n",
      "epoch: 15, iter: 6000, loss: 1.300208330154419\n",
      "epoch: 16, iter: 0, loss: 1.1911780834197998\n",
      "epoch: 16, iter: 2000, loss: 1.4558870792388916\n",
      "epoch: 16, iter: 4000, loss: 1.5753446817398071\n",
      "epoch: 16, iter: 6000, loss: 1.4166936874389648\n",
      "epoch: 17, iter: 0, loss: 1.3704586029052734\n",
      "epoch: 17, iter: 2000, loss: 1.2622830867767334\n",
      "epoch: 17, iter: 4000, loss: 1.5236084461212158\n",
      "epoch: 17, iter: 6000, loss: 1.534470796585083\n",
      "epoch: 18, iter: 0, loss: 1.3541836738586426\n",
      "epoch: 18, iter: 2000, loss: 1.6585474014282227\n",
      "epoch: 18, iter: 4000, loss: 1.3389438390731812\n",
      "epoch: 18, iter: 6000, loss: 1.5489864349365234\n",
      "epoch: 19, iter: 0, loss: 1.1057703495025635\n",
      "epoch: 19, iter: 2000, loss: 1.2624340057373047\n",
      "epoch: 19, iter: 4000, loss: 1.4277023077011108\n",
      "epoch: 19, iter: 6000, loss: 1.1980345249176025\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for e in range(NUM_EPOCHS):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        center_node, pos_nodes, neg_nodes = map(lambda x:x.long().to(DEVICE), batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = model(center_node, pos_nodes, neg_nodes).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if i % 2000 == 0:\n",
    "            print(\"epoch: {}, iter: {}, loss: {}\".format(e, i, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dict = dict(zip(node2idx.keys(),model.get_embed()))\n",
    "pd.DataFrame(embed_dict).T.to_csv('embedding/prob_walk_whole_graph_'+str(EMBED_DIM)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('loss/prob_walk_whole_graph_'+str(EMBED_DIM)+'.npy',losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
